import numpy as np
import faiss
import pickle
import os
import json
from sentence_transformers import SentenceTransformer

# Chemins des fichiers
JSON_PATH = "pristini_programs.json"
OUTPUT_DIR = "rag_output"
FAISS_INDEX_OUTPUT = os.path.join(OUTPUT_DIR, "faiss.index")
SENTENCES_OUTPUT = os.path.join(OUTPUT_DIR, "sentences.pkl")
METADATA_OUTPUT = os.path.join(OUTPUT_DIR, "metadata.pkl")

with open(JSON_PATH, "r", encoding="utf-8") as f:
    data = json.load(f)

# Correction : si data est une liste contenant une liste
if isinstance(data[0], list):
    data = data[0]

# Chargement du mod√®le d'embedding
model = SentenceTransformer("all-MiniLM-L6-v2")

sentences = []
metadata = []

# Conversion des objets JSON en phrases et metadata
"""for program in data:
    desc = " ".join(program.get("description_blocks", []))
    modules = " ".join([f"{k} : {', '.join(v)}." for k, v in program.get("modules", {}).items()])

    # Construction de la phrase
    sentence = (
    f"üåü Programme : {program.get('title', 'Titre inconnu')}\n"
    f"üè´ √âtablissement : {program.get('delivered_by', '√âtablissement inconnu')}\n"
    f"‚è± Dur√©e : {program.get('duration', 'Non sp√©cifi√©e')}\n\n"
    f"üìù Description :\n{desc if desc else 'Aucune description disponible'}\n\n"
    f"üìö Modules cl√©s :\n{modules if modules else 'Modules non disponibles'}\n\n"
    f"üîó Lien vers le programme : {program.get('url', 'URL non disponible')}\n"
    f"üìÖ Prochaine session : {program.get('start_date', '√Ä d√©finir')}"
)

sentences.append(sentence)

metadata.append({
    "Programme": program.get("title", "Titre inconnu"),
    "√âtablissement": program.get("delivered_by", "√âtablissement inconnu"),
    "Dur√©e": program.get("duration", "Non sp√©cifi√©e"),
    "Type": "Master" if "master" in program.get('title', '').lower() else "Autre",
    "URL": program.get("url", ""),
    "Langue": program.get("language", "Anglais"),
    "Modalit√©": program.get("modality", "Pr√©sentiel"),
    "Cr√©dits ECTS": program.get("ects", "Non sp√©cifi√©"),
    "Dipl√¥me d√©livr√©": program.get("diploma", "Master"),
    "Admission": program.get("admission", "Sur dossier"),
    "Prix": program.get("price", "Non communiqu√©")
})
print("G√©n√©ration des embeddings...")"""

for program in data:
    # V√©rifie que program est bien un dict et qu'il contient la cl√© 'title'
    if isinstance(program, dict) and 'title' in program:
        desc = " ".join(program.get("description_blocks", []))
        modules = " ".join([f"{k} : {', '.join(v)}." for k, v in program.get("modules", {}).items()])

        sentence = (
            f"üåü Programme : {program.get('title')}\n"
            f"üè´ √âtablissement : {program.get('delivered_by')}\n"
            f"‚è± Dur√©e : {program.get('duration')}\n\n"
            f"üìù Description :\n{desc}\n\n"
            f"üìö Modules cl√©s :\n{modules}\n\n"
            f"üîó Lien vers le programme : {program.get('url')}\n"
            f"üìÖ Prochaine session : {program.get('start_date', '√Ä d√©finir')}"
        )
        sentences.append(sentence)

        metadata.append({
            "Programme": program.get("title"),
            "√âtablissement": program.get("delivered_by"),
            "Dur√©e": program.get("duration"),
            "Type": "Master" if "master" in program.get('title', '').lower() else "Autre",
            "URL": program.get("url", ""),
            "Langue": program.get("language", "Anglais"),
            "Modalit√©": program.get("modality", "Pr√©sentiel"),
            "Cr√©dits ECTS": program.get("ects", "Non sp√©cifi√©"),
            "Dipl√¥me d√©livr√©": program.get("diploma", "Master"),
            "Admission": program.get("admission", "Sur dossier"),
            "Prix": program.get("price", "Non communiqu√©")
        })


# Calcul des embeddings
embeddings = model.encode(sentences, show_progress_bar=True)

# Construction de l'index FAISS
index = faiss.IndexFlatL2(embeddings.shape[1])
index.add(np.array(embeddings))

# Sauvegarde des fichiers
#os.makedirs(OUTPUT_DIR, exist_ok=True)
faiss.write_index(index, FAISS_INDEX_OUTPUT)

with open(SENTENCES_OUTPUT, "wb") as f:
    pickle.dump(sentences, f)
with open(METADATA_OUTPUT, "wb") as f:
    pickle.dump(metadata, f)

print("‚úÖ Index FAISS, phrases et metadata sauvegard√©s dans 'rag_output/'")
