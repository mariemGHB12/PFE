import os
import json
import pickle
import numpy as np
import faiss
from sentence_transformers import SentenceTransformer

def build_index(json_path, output_dir):
    # PrÃ©paration des chemins de sortie
    faiss_index_output = os.path.join(output_dir, "faiss.index")
    sentences_output = os.path.join(output_dir, "sentences.pkl")
    metadata_output = os.path.join(output_dir, "metadata.pkl")

    # Chargement des donnÃ©es
    with open(json_path, "r", encoding="utf-8") as f:
        raw_data = json.load(f)

    programs = [
        p for p in raw_data
        if isinstance(p, dict) and "title" in p and "description_blocks" in p
    ]

    model = SentenceTransformer("all-MiniLM-L6-v2")

    sentences = []
    metadata = []

    for program in programs:
        desc = " ".join(program.get("description_blocks", []))
        modules = " ".join([
            f"{k} : {', '.join(v)}." for k, v in program.get("modules", {}).items()
        ])

        sentence = (
            f"ğŸŒŸ Programme : {program.get('title', 'Titre inconnu')}\n"
            f"ğŸ« Ã‰tablissement : {program.get('delivered_by', 'Ã‰tablissement inconnu')}\n"
            f"â± DurÃ©e : {program.get('duration', 'Non spÃ©cifiÃ©e')}\n\n"
            f"ğŸ“ Description :\n{desc if desc else 'Aucune description disponible'}\n\n"
            f"ğŸ“š Modules clÃ©s :\n{modules if modules else 'Modules non disponibles'}\n\n"
            f"ğŸ”— Lien vers le programme : {program.get('url', 'URL non disponible')}\n"
            f"ğŸ“… Prochaine session : {program.get('start_date', 'Ã€ dÃ©finir')}"
        )

        sentences.append(sentence)
        metadata.append({
            "Programme": program.get("title", "Titre inconnu"),
            "Ã‰tablissement": program.get("delivered_by", "Ã‰tablissement inconnu"),
            "DurÃ©e": program.get("duration", "Non spÃ©cifiÃ©e"),
            "Type": "Master" if "master" in program.get('title', '').lower() else "Autre",
            "URL": program.get("url", ""),
            "Langue": program.get("language", "FranÃ§ais"),
            "ModalitÃ©": program.get("modality", "PrÃ©sentiel"),
            "CrÃ©dits ECTS": program.get("ects", "Non spÃ©cifiÃ©"),
            "DiplÃ´me dÃ©livrÃ©": program.get("diploma", "Master"),
            "Admission": program.get("admission", "Sur dossier"),
            "Prix": program.get("price", "Non communiquÃ©")
        })

    print("ğŸ” GÃ©nÃ©ration des embeddings...")
    embeddings = model.encode(sentences, show_progress_bar=True)
    embeddings = np.array(embeddings).astype("float32")

    print("ğŸ’¾ Sauvegarde de l'index FAISS et des donnÃ©es...")
    os.makedirs(output_dir, exist_ok=True)

    index = faiss.IndexFlatL2(embeddings.shape[1])
    index.add(embeddings)
    faiss.write_index(index, faiss_index_output)

    with open(sentences_output, "wb") as f:
        pickle.dump(sentences, f)

    with open(metadata_output, "wb") as f:
        pickle.dump(metadata, f)

    print(f"âœ… Index FAISS et donnÃ©es sauvegardÃ©es dans '{output_dir}/'")